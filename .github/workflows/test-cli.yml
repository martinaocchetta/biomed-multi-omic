# This workflow will install Python dependencies, run tests and lint with a variety of Python versions
# For more information see: https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-python

name: Test inference and finetune CLI

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  workflow_dispatch:

jobs:
  build:

    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.13"]

    steps:
    - uses: actions/checkout@v4
    - name: Install the latest version of uv and set the python version
      uses: astral-sh/setup-uv@v5
      with:
        python-version: ${{ matrix.python-version }}
    - name: Install cURL Headers (for hic-straw install/build)
      run: sudo apt-get install libcurl4-openssl-dev
    - name: Install package
      run: uv pip install -q .
    - name: Print environment
      run: uv pip freeze
    - name: Cache Hugging Face Transformers / Datasets
      uses: actions/cache@v4
      with:
        path: ~/.cache/huggingface
        key: hf-cache-${{ runner.os }}-${{ matrix.python-version }}
        restore-keys: hf-cache-${{ runner.os }}-
    - name: Download and preprocess Scanpy sample file
      run: |
        python -c "
        import scanpy as sc
        import numpy as np
        import bmfm_targets.datasets.datasets_utils as du
        import scipy.sparse as sp

        ad = sc.datasets.pbmc3k()
        random_state=42
        rng = np.random.default_rng(random_state)
        ad = ad[rng.choice(ad.shape[0], 50, replace=False)].copy()
        ad.X = ad.X.tocsr() if sp.issparse(ad.X) else sp.csr_matrix(ad.X)
        ad.obs['split_random'] = du.get_random_split(ad.obs, {'train':0.8, 'dev': 0.1, 'test': 0.1}, random_state)
        splits_array = rng.choice(['celltype1', 'celltype2', 'celltype3', 'celltype4'], size=ad.shape[0], p=[0.25]*4)
        ad.obs['celltype'] = ad.obs.assign(split=splits_array).pop('split')
        ad.write_h5ad('/home/runner/my_data_file.h5ad')
        "
                echo "MY_DATA_FILE=/home/runner/my_data_file.h5ad" >> $GITHUB_ENV
    - name: Test MLM+RDA inference
      run: bmfm-targets-run -cn predict input_file=$MY_DATA_FILE working_dir=/tmp/runs data_module.collation_strategy=language_modeling data_module.log_normalize_transform=false data_module.max_length=256 checkpoint=ibm-research/biomed.rna.bert.110m.mlm.rda.v1  task.accelerator=cpu task.precision=32 && rm -rf /tmp/runs/*
    - name: Test MLM+Multitask inference
      run: bmfm-targets-run -cn predict input_file=$MY_DATA_FILE working_dir=/tmp/runs data_module.max_length=256 checkpoint=ibm-research/biomed.rna.bert.110m.mlm.multitask.v1 task.accelerator=cpu task.precision=32 data_module.log_normalize_transform=false && rm -rf /tmp/runs/*
    - name: Test WCED+Multitask inference
      run: bmfm-targets-run -cn predict input_file=$MY_DATA_FILE working_dir=/tmp/runs data_module.max_length=256 checkpoint=ibm-research/biomed.rna.bert.110m.wced.multitask.v1 task.accelerator=cpu task.precision=32 data_module.log_normalize_transform=false && rm -rf /tmp/runs/*
    - name: Test WCED inference
      run: bmfm-targets-run -cn predict input_file=$MY_DATA_FILE working_dir=/tmp/runs data_module.collation_strategy=language_modeling data_module.max_length=256 checkpoint=ibm-research/biomed.rna.bert.110m.wced.v1 task.accelerator=cpu task.precision=32 data_module.log_normalize_transform=false && rm -rf /tmp/runs/*
    # finetune tests
    - name: Test MLM+RDA finetune
      run: bmfm-targets-run -cn finetune label_column_name=celltype split_column_name=null input_file=$MY_DATA_FILE working_dir=/tmp/runs data_module.log_normalize_transform=false checkpoint=ibm-research/biomed.rna.bert.110m.mlm.rda.v1 accelerator=cpu data_module.max_length=256 max_epochs=2 val_check_interval=null data_module.num_workers=0 && rm -rf /tmp/runs/*
    - name: Test MLM+Multitask finetune
      run: bmfm-targets-run -cn finetune label_column_name=celltype split_column_name=null input_file=$MY_DATA_FILE working_dir=/tmp/runs checkpoint=ibm-research/biomed.rna.bert.110m.mlm.multitask.v1 accelerator=cpu data_module.max_length=256 max_epochs=2 val_check_interval=null data_module.num_workers=0 data_module.log_normalize_transform=false && rm -rf /tmp/runs/*
    - name: Test WCED+Multitask finetune
      run: bmfm-targets-run -cn finetune label_column_name=celltype split_column_name=null input_file=$MY_DATA_FILE working_dir=/tmp/runs checkpoint=ibm-research/biomed.rna.bert.110m.wced.multitask.v1 accelerator=cpu data_module.max_length=256 max_epochs=2 val_check_interval=null data_module.num_workers=0 data_module.log_normalize_transform=false && rm -rf /tmp/runs/*
    - name: Test WCED finetune
      run: bmfm-targets-run -cn finetune label_column_name=celltype split_column_name=null input_file=$MY_DATA_FILE working_dir=/tmp/runs checkpoint=ibm-research/biomed.rna.bert.110m.wced.v1 accelerator=cpu data_module.max_length=256 max_epochs=2 val_check_interval=null data_module.num_workers=0 data_module.log_normalize_transform=false && rm -rf /tmp/runs/*
    # pretrain tests
    - name: Test MLM+RDA pretrain
      run: bmfm-targets-run -cn rda_mlm input_file=$MY_DATA_FILE working_dir=/tmp/runs checkpoint=ibm-research/biomed.rna.bert.110m.mlm.rda.v1 data_module.max_length=256 task.max_epochs=1 task.accelerator=cpu task.precision=32 && rm -rf /tmp/runs/*
